{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Finetuning Torchvision Models\n",
    "=============================\n",
    "\n",
    "**Author:** `Nathan Inkawhich <https://github.com/inkawhich>`__\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.7.1\n",
      "Torchvision Version:  0.8.2\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function \n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Top level data directory. Here we assume the format of the directory conforms \n",
    "#   to the ImageFolder structure\n",
    "data_dir = \"./hymenoptera_data\"\n",
    "\n",
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
    "model_name = \"squeezenet\"\n",
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = 2\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 8\n",
    "\n",
    "# Number of epochs to train for \n",
    "num_epochs = 10\n",
    "\n",
    "# Flag for feature extracting. When False, we finetune the whole model, \n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize and Reshape the Networks\n",
    "-----------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SqueezeNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (3): Fire(\n",
      "      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Fire(\n",
      "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Fire(\n",
      "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (7): Fire(\n",
      "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (8): Fire(\n",
      "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (9): Fire(\n",
      "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (10): Fire(\n",
      "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (12): Fire(\n",
      "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes) \n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3 \n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "    \n",
    "    return model_ft, input_size\n",
    "\n",
    "# Initialize the model for this run\n",
    "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "\n",
    "# Print the model we just instantiated\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data\n",
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://download.pytorch.org/tutorial/hymenoptera_data.zip\n",
    "#!unzip hymenoptera_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Datasets and Dataloaders...\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "# Create training and validation datasets\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t classifier.1.weight\n",
      "\t classifier.1.bias\n"
     ]
    }
   ],
   "source": [
    "# Send the model to GPU\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are \n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Training and Validation Step\n",
    "--------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 0.5267 Acc: 0.7582\n",
      "val Loss: 0.2964 Acc: 0.8954\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.2459 Acc: 0.8934\n",
      "val Loss: 0.2604 Acc: 0.9281\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.2057 Acc: 0.9180\n",
      "val Loss: 0.2857 Acc: 0.9281\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.2399 Acc: 0.8811\n",
      "val Loss: 0.2997 Acc: 0.9216\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.2197 Acc: 0.8975\n",
      "val Loss: 0.3189 Acc: 0.8954\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.1807 Acc: 0.9180\n",
      "val Loss: 0.2726 Acc: 0.9412\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.1953 Acc: 0.9057\n",
      "val Loss: 0.2932 Acc: 0.9412\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.1172 Acc: 0.9426\n",
      "val Loss: 0.3360 Acc: 0.9346\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.1237 Acc: 0.9426\n",
      "val Loss: 0.3475 Acc: 0.9216\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.1233 Acc: 0.9508\n",
      "val Loss: 0.3719 Acc: 0.9281\n",
      "\n",
      "Training complete in 1m 26s\n",
      "Best val Acc: 0.941176\n"
     ]
    }
   ],
   "source": [
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and evaluate\n",
    "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison with Model Trained from Scratch\n",
    "------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n",
      "train Loss: 0.7158 Acc: 0.5082\n",
      "val Loss: 0.6931 Acc: 0.4575\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n",
      "train Loss: 0.6931 Acc: 0.4959\n",
      "val Loss: 0.6931 Acc: 0.4575\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n",
      "train Loss: 0.6932 Acc: 0.5041\n",
      "val Loss: 0.6931 Acc: 0.4575\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n",
      "train Loss: 0.6932 Acc: 0.4836\n",
      "val Loss: 0.6931 Acc: 0.4575\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n",
      "train Loss: 0.6932 Acc: 0.5123\n",
      "val Loss: 0.6931 Acc: 0.4575\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n",
      "train Loss: 0.6931 Acc: 0.5328\n",
      "val Loss: 0.6931 Acc: 0.4575\n",
      "\n",
      "Epoch 7/10\n",
      "----------\n",
      "train Loss: 0.6931 Acc: 0.5000\n",
      "val Loss: 0.6931 Acc: 0.4575\n",
      "\n",
      "Epoch 8/10\n",
      "----------\n",
      "train Loss: 0.6931 Acc: 0.5041\n",
      "val Loss: 0.6931 Acc: 0.4575\n",
      "\n",
      "Epoch 9/10\n",
      "----------\n",
      "train Loss: 0.6931 Acc: 0.5082\n",
      "val Loss: 0.6931 Acc: 0.4575\n",
      "\n",
      "Epoch 10/10\n",
      "----------\n",
      "train Loss: 0.6931 Acc: 0.5164\n",
      "val Loss: 0.6931 Acc: 0.4575\n",
      "\n",
      "Training complete in 2m 27s\n",
      "Best val Acc: 0.457516\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the non-pretrained version of the model used for this run\n",
    "scratch_model,_ = initialize_model(model_name, num_classes, feature_extract=False, use_pretrained=False)\n",
    "scratch_model = scratch_model.to(device)\n",
    "scratch_optimizer = optim.SGD(scratch_model.parameters(), lr=0.001, momentum=0.9)\n",
    "scratch_criterion = nn.CrossEntropyLoss()\n",
    "_,scratch_hist = train_model(scratch_model, dataloaders_dict, scratch_criterion, scratch_optimizer, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))\n",
    "\n",
    "# Plot the training curves of validation accuracy vs. number \n",
    "#  of training epochs for the transfer learning method and\n",
    "#  the model trained from scratch\n",
    "ohist = []\n",
    "shist = []\n",
    "\n",
    "ohist = [h.cpu().numpy() for h in hist]\n",
    "shist = [h.cpu().numpy() for h in scratch_hist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Validation Accuracy vs. Number of Training Epochs\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
    "plt.plot(range(1,num_epochs+1),shist,label=\"Scratch\")\n",
    "plt.ylim((0,1.))\n",
    "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
